 Consultants often explain that the reason a design broke for which
they were responsible was that the circumstances were
impossible: ‘the client didn’t want a secure system,
but just the most security I could fit on his product
in one week on a budget of $10,000’. It is important
to realize that this is not just management stupidity. The huge first-mover advantages that can arise
in economic systems with strong positive feedback are
the origin of the so-called “Microsoft philosophy” of
‘we’ll ship it on Tuesday and get it right by version
3’

Network economics has many other effects on security engineering. Rather than using a standard, well
analyzed and tested architecture, companies often go
for a proprietary obscure one – to increase customer
lock-in and increase the investment that competitors
have to make to create compatible products.

why is it that, even in relatively competitive security product markets, the bad products
tend to drive out the good?
The theory of asymmetric information gives us an
explanation of one of the mechanisms. Consider a used
car market, on which there are 100 good cars (the
‘plums’), worth $3000 each, and 100 rather troublesome ones (the ‘lemons’), each of which is worth only
$1000. The vendors know which is which, but the
buyers don’t. So what will be the equilibrium price of
used cars?
If customers start off believing that the probability
they will get a plum is equal to the probability they
will get a lemon, then the market price will start off
at $2000. However, at that price only lemons will be
offered for sale, and once the buyers observe this, the
price will drop rapidly to $1000 with no plums being
sold at all. In other words, when buyers don’t have as
much information about the quality of the products
as sellers do, there will be severe downward pressure
on both price and quality. Infosec people frequently
complain about this in many markets for the products and components we use; the above insight, due
to Akerlof [1], explains why it happens

The problem of bad products driving out good ones
can be made even worse when the people evaluating them aren’t the people who suffer when they fail.
Much has been written on the ways in which corporate performance can be adversely affected when executives have incentives at odds with the welfare of their
employer. For example, managers often buy products
and services which they know to be suboptimal or even
defective, but which are from big name suppliers. This
is known to minimize the likelihood of getting fired
when things go wrong. Corporate lawyers don’t condemn this as fraud, but praise it as ‘due diligence’.
Over the last decade of the twentieth century, many
businesses have sought to fix this problem by extending stock options to ever more employees. However,
these incentives don’t appear to be enough to ensure
prudent practice by security managers. (This might
be an interesting topic for a PhD; does it come down
to the fact that security managers also have less information about threats, and so cannot make rational
decisions about protection versus insurance, or is it
simply due to adverse selection among security managers?)
